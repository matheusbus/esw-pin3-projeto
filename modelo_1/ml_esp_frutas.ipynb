{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbdc6dd-9bd7-4b67-9e31-81a5147a109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "260cbcc7-285c-4d54-b24d-327f00d2e1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de imagens de morango: 306\n",
      "Contagem de imagens de pêssego: 304\n",
      "Contagem de imagens de romã: 311\n"
     ]
    }
   ],
   "source": [
    "## 1. Dataset das imagens\n",
    "dataset_dir = os.path.join(os.getcwd(), 'imagens')\n",
    "dataset_morango_dir = os.path.join(dataset_dir, 'morango')\n",
    "dataset_pessego_dir = os.path.join(dataset_dir, 'pessego')\n",
    "dataset_roma_dir = os.path.join(dataset_dir, 'roma')\n",
    "\n",
    "dataset_morango_len = len(os.listdir(dataset_morango_dir))\n",
    "dataset_pessego_len = len(os.listdir(dataset_pessego_dir))\n",
    "dataset_roma_len = len(os.listdir(dataset_roma_dir))\n",
    "\n",
    "print(f'Contagem de imagens de morango: {dataset_morango_len}')\n",
    "print(f'Contagem de imagens de pêssego: {dataset_pessego_len}')\n",
    "print(f'Contagem de imagens de romã: {dataset_roma_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202294f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aplicando o rebalanceamento do dataset\n",
    "# -> Utilizada a técnica de 'data augmentation' para gerar novas imagens de morango e pessego\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Criar um objeto ImageDataGenerator para data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,          # Faixa de rotação aleatória em graus\n",
    "    width_shift_range=0.2,      # Faixa de deslocamento horizontal aleatório (como uma fração da largura total)\n",
    "    height_shift_range=0.2,     # Faixa de deslocamento vertical aleatório (como uma fração da altura total)\n",
    "    shear_range=0.2,            # Faixa de cisalhamento aleatório (em radianos)\n",
    "    zoom_range=0.2,             # Faixa de zoom aleatório\n",
    "    horizontal_flip=True,      # Inverter aleatoriamente as imagens horizontalmente (espelhamento)\n",
    "    fill_mode='nearest'        # Estratégia de preenchimento usada para preencher novos pixels gerados após a rotação ou deslocamento\n",
    ")\n",
    "\n",
    "if (dataset_morango_len == 250) or (dataset_pessego_len == 250): \n",
    "    numero_imagens_aumentadas = 61\n",
    "    classes_aumentadas = ['morango', 'pessego']\n",
    "\n",
    "    for classe in classes_aumentadas:\n",
    "        # Diretório da classe atual\n",
    "        diretorio_classe = os.path.join(dataset_dir, classe)\n",
    "        \n",
    "        # Criar diretório para a classe aumentada, se não existir\n",
    "        diretorio_destino_classe = os.path.join(dataset_dir, classe)\n",
    "        os.makedirs(diretorio_destino_classe, exist_ok=True)\n",
    "        \n",
    "        # Lista de arquivos de imagem na classe atual\n",
    "        imagens_classe = os.listdir(diretorio_classe)\n",
    "        \n",
    "        # Selecionar aleatoriamente algumas imagens existentes para data augmentation\n",
    "        indices_amostra = np.random.choice(len(imagens_classe), numero_imagens_aumentadas, replace=True)\n",
    "        \n",
    "        # Para cada imagem de amostra selecionada\n",
    "        for indice in indices_amostra:\n",
    "            imagem_nome = imagens_classe[indice]\n",
    "            imagem_path = os.path.join(diretorio_classe, imagem_nome)\n",
    "            \n",
    "            # Carregar imagem\n",
    "            imagem = Image.open(imagem_path)\n",
    "            imagem_array = np.array(imagem)\n",
    "            imagem_array = imagem_array.reshape((1,) + imagem_array.shape)  # Reshape para (1, altura, largura, canais)\n",
    "            \n",
    "            # Gerar imagens aumentadas e salvar no diretório de destino\n",
    "            for i, batch in enumerate(datagen.flow(imagem_array, batch_size=1)):\n",
    "                if i >= 1:  # Quantidade de imagens aumentadas a serem geradas por imagem de amostra\n",
    "                    break\n",
    "                imagem_aumentada = batch[0].astype(np.uint8)  # Converter de volta para o formato de imagem\n",
    "                nova_imagem_nome = f\"{os.path.splitext(imagem_nome)[0]}_aug_{i}.jpg\"\n",
    "                nova_imagem_path = os.path.join(diretorio_destino_classe, nova_imagem_nome)\n",
    "                nova_imagem = Image.fromarray(imagem_aumentada)\n",
    "                nova_imagem.save(nova_imagem_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f11c96a-7b60-4ece-b705-d472939d7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Definição e separação dos dados de treinamento e dados de teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "projeto_dir = os.getcwd() # Diretório do projeto\n",
    "dataset_treinamento_dir = os.path.join(projeto_dir, 'imagens_treinamento') # Caminho para imagens_treinamento\n",
    "dataset_teste_dir = os.path.join(projeto_dir, 'imagens_teste') # Caminho para imagens_teste\n",
    "\n",
    "proporcao_dataset_treinamento = 0.8 # 80% será utilizado no treinamento\n",
    "proporcao_dataset_teste = 1 - proporcao_dataset_treinamento # 20% será utilizado no teste\n",
    "random_seed = 42 # A resposta para a Vida - segundo livro de Aurélien Géron - gerar com random\n",
    "\n",
    "classes = ['morango', 'pessego', 'roma']\n",
    "\n",
    "# Função que executará a separação das imagens (utiliza algoritmo de aleatoriedade)\n",
    "def split_dataset_to_train_and_test(classe):\n",
    "    dataset_treinamento_classe_dir = os.path.join(dataset_treinamento_dir, classe) # Dir. destino treinamento classe\n",
    "    dataset_teste_classe_dir = os.path.join(dataset_teste_dir, classe) # Dir. destino teste classe\n",
    "\n",
    "    dataset_classe_dir = os.path.join(projeto_dir, 'imagens', classe) # Dir. origem imagens classe\n",
    "    imagens_classe = [os.path.join(dataset_classe_dir, img) for img in os.listdir(dataset_classe_dir)] # Popular lista com imagens\n",
    "\n",
    "    imagens_treinamento_classe, imagens_teste_classe = train_test_split(imagens_classe, test_size=proporcao_dataset_teste, random_state=random_seed) # Algoritmo que separa aleatoriamente as imagens de treinamento e de teste\n",
    "\n",
    "    # Criação dos diretórios de treinamento e teste para a classe\n",
    "    os.makedirs(dataset_treinamento_classe_dir, exist_ok=True)\n",
    "    os.makedirs(dataset_teste_classe_dir, exist_ok=True)\n",
    "\n",
    "    # Copia as imagens de treinamento para a pasta de treinamento da classe em questão\n",
    "    for imagem in imagens_treinamento_classe:\n",
    "        shutil.copy(imagem, dataset_treinamento_classe_dir) \n",
    "\n",
    "    # Copia as imagens de teste para a pasta de teste da classe em questão\n",
    "    for imagem in imagens_teste_classe:\n",
    "        shutil.copy(imagem, dataset_teste_classe_dir) \n",
    "\n",
    "# Verifica se os diretórios de treinamento e teste já existem\n",
    "if not os.path.exists(dataset_treinamento_dir) or not os.path.exists(dataset_teste_dir):\n",
    "    # Cria os diretórios de treinamento e teste\n",
    "    os.makedirs(dataset_treinamento_dir, exist_ok=True)\n",
    "    os.makedirs(dataset_teste_dir, exist_ok=True)\n",
    "    # Para cada classe, executa a função de divisão de dados\n",
    "    for classe in classes:\n",
    "        split_dataset_to_train_and_test(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c7c32a-e4e8-435b-b67d-0e8ee0e51f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de imagens de morango para treinamento: 244\n",
      "Contagem de imagens de morango para teste: 62\n",
      "Contagem de imagens de pêssego para treinamento: 243\n",
      "Contagem de imagens de pêssego para teste: 61\n",
      "Contagem de imagens de romã para treinamento: 248\n",
      "Contagem de imagens de romã para teste: 63\n"
     ]
    }
   ],
   "source": [
    "# Como ficou dataset de treinamento e de testes:\n",
    "\n",
    "dataset_treinamento_morango_len = len(os.listdir(os.path.join(dataset_treinamento_dir, 'morango')))\n",
    "dataset_teste_morango_len = len(os.listdir(os.path.join(dataset_teste_dir, 'morango')))\n",
    "dataset_treinamento_pessego_len = len(os.listdir(os.path.join(dataset_treinamento_dir, 'pessego')))\n",
    "dataset_teste_pessego_len = len(os.listdir(os.path.join(dataset_teste_dir, 'pessego')))\n",
    "dataset_treinamento_roma_len = len(os.listdir(os.path.join(dataset_treinamento_dir, 'roma')))\n",
    "dataset_teste_roma_len = len(os.listdir(os.path.join(dataset_teste_dir, 'roma')))\n",
    "\n",
    "print(f'Contagem de imagens de morango para treinamento: {dataset_treinamento_morango_len}')\n",
    "print(f'Contagem de imagens de morango para teste: {dataset_teste_morango_len}')\n",
    "print(f'Contagem de imagens de pêssego para treinamento: {dataset_treinamento_pessego_len}')\n",
    "print(f'Contagem de imagens de pêssego para teste: {dataset_teste_pessego_len}')\n",
    "print(f'Contagem de imagens de romã para treinamento: {dataset_treinamento_roma_len}')\n",
    "print(f'Contagem de imagens de romã para teste: {dataset_teste_roma_len}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e820b6a-891f-4d1d-8934-59dc4f5c427f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matheus/Documentos/GitHub/esw-pin3-projeto/modelo_1/imagens_treinamento\n",
      "/home/matheus/Documentos/GitHub/esw-pin3-projeto/modelo_1/imagens_teste\n",
      "Found 735 files belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 186 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "## 4. Pré-processamento das imagens\n",
    "## --> Definir tamanho de entrada das minhas imagens (em px)\n",
    "## --> Definir qual estratégia de conversão adotar (scaling da imagem / foco no centro da imagem ignorando periferia / recortar imagem até no limite do tamanho definido e ignorar o restante)\n",
    "\n",
    "'''\n",
    "Considerações sobre a abordagem:\n",
    "O pré-processamento é feito pela função \"tf.keras.preprocessing.image_dataset_from_directory\". Essa função permite especificar o tamanho das imagens e aplica automaticamente a normalização durante o carregamento das imagens. Além disso, aplica embaralhamento\n",
    "e carrega as imagens em lotes (batch). Por fim, as imagens são consideradas como tensores do TensorFlow.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "image_width = 300\n",
    "image_heigth = 300\n",
    "image_size = (image_width, image_heigth)\n",
    "\n",
    "image_color_channel = 3\n",
    "image_color_channel_size = 255\n",
    "image_shape = image_size + (image_color_channel,)\n",
    "\n",
    "batch_size = 32 # Valor que vou puxar do dataset por vez\n",
    "epoch = 20 # Quantidade de vezes que vou percorrer meu dataset inteiro\n",
    "learning_rate = 0.0001 # Taxa de aprendizagem\n",
    "\n",
    "classes = ['morango', 'pessego', 'roma']\n",
    "\n",
    "projeto_dir = os.getcwd()\n",
    "dataset_treinamento_dir = os.path.join(projeto_dir, 'imagens_treinamento')\n",
    "dataset_teste_dir = os.path.join(projeto_dir, 'imagens_teste')\n",
    "\n",
    "print(dataset_treinamento_dir)\n",
    "print(dataset_teste_dir)\n",
    "\n",
    "data_set_treinamento = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_treinamento_dir,\n",
    "    image_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True, # Embaralhamento\n",
    "    label_mode='categorical' # Carrega os dados em formato one-hot\n",
    ")\n",
    "\n",
    "data_set_teste = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_teste_dir,\n",
    "    image_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False, # Não é necessário embaralhar os dados de teste\n",
    "    label_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fe27dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Definição da arquitetura da rede neural do modelo\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "\n",
    "# Arquitetura da rede do modelo implementado:\n",
    "model = Sequential([\n",
    "  # Definição do tipo de entrada: imagens de 300x300 pixels com 3 canais de cores (RGB) \n",
    "  Input(shape=(300,300,3)),\n",
    "\n",
    "  # Primeira camada: convolucional com 32 filtros de tamanho 3x3, utilizando a função de ativação ReLU\n",
    "  Conv2D(32, (3,3), activation='relu'),\n",
    "\n",
    "  # Camada de normalização de batch, para normalizar a ativação da camada anterior\n",
    "  BatchNormalization(),\n",
    "\n",
    "  # Camada de MaxPooling, detalhada no documento de especificação do projeto\n",
    "  MaxPooling2D((2,2)),\n",
    "\n",
    "  # Mais uma camada Conv2D, com 64 filtros de tamanho 3x3, com função de ativação ReLU\n",
    "  Conv2D(64, (3,3), activation='relu'),\n",
    "\n",
    "  # Outra camada de normalização de batch, para normalizar a ativação da camada anterior\n",
    "  BatchNormalization(),\n",
    "\n",
    "  # Camada de MaxPooling, detalhada no documento de especificação do projeto\n",
    "  MaxPooling2D((2,2)),\n",
    "\n",
    "  # Camada de achatamento (Flatten) para transformar os mapas de características 2D em um vetor 1D\n",
    "  Flatten(),\n",
    "  \n",
    "  # Camada densa (totalmente conectada) com 128 neurônios e função de ativação ReLU\n",
    "  Dense(128, activation='relu'),\n",
    "  \n",
    "  # Mias uma camada de normalização de batch, para normalizar a ativação da camada anterior\n",
    "  BatchNormalization(),\n",
    "\n",
    "  # Mais uma camada densa com 64 neurônios e função de ativação ReLU\n",
    "  Dense(64, activation='relu'),\n",
    "  \n",
    "  # Camada de Dropout para prevenir overfitting, desativando aleatoriamente 50% dos neurônios\n",
    "  Dropout(0.5),\n",
    "  \n",
    "  # Camada de saída com 3 neurônios (um para cada classe) e função de ativação softmax para a classificação multiclasse\n",
    "  Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilação do modelo\n",
    "# Aqui, utilizamos a função de perda conforme espeficicado no documento do projeto\n",
    "# Função de perda: crossentropy, que irá calcular a diferença entre as previsões realizadas pelo modelo e os rótulos verdadeiros associados aos dados de treinamento.\n",
    "\n",
    "# Além disso, testaremos 3 tipos de funções de otimização:\n",
    "\n",
    "# Função de otimização Adam\n",
    "model.compile(optimizer=Adam(learning_rate), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "# Função de otimização SGD\n",
    "# model.compile(optimizer=SGD(), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "# Função de otimização RMSprop\n",
    "# model.compile(optimizer=RMSprop(), loss=CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bc18158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 6s/step - accuracy: 0.5911 - loss: 1.2363 - val_accuracy: 0.4355 - val_loss: 8.8659\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 6s/step - accuracy: 0.7868 - loss: 0.5642 - val_accuracy: 0.5914 - val_loss: 2.7070\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 5s/step - accuracy: 0.8734 - loss: 0.3712 - val_accuracy: 0.5269 - val_loss: 1.4865\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 5s/step - accuracy: 0.9033 - loss: 0.2868 - val_accuracy: 0.6183 - val_loss: 0.8187\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 5s/step - accuracy: 0.9235 - loss: 0.2405 - val_accuracy: 0.8172 - val_loss: 0.4999\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 5s/step - accuracy: 0.9510 - loss: 0.1896 - val_accuracy: 0.8333 - val_loss: 0.4396\n",
      "Epoch 7/20\n",
      "\u001b[1m11/23\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m59s\u001b[0m 5s/step - accuracy: 0.9546 - loss: 0.1607 "
     ]
    }
   ],
   "source": [
    "# 6. Treinamento do modelo\n",
    "\n",
    "# É passado o dataset de treinamento, a quantidade de épocas (quantas vezes vai percorrer o dataset) e o dataset de validação\n",
    "model.fit(\n",
    "  data_set_treinamento,\n",
    "  epochs=epoch,\n",
    "  validation_data=data_set_teste\n",
    ")\n",
    "\n",
    "# Avaliação do modelo\n",
    "teste_perca, teste_acuracia = model.evaluate(data_set_teste)\n",
    "print('Teste acurácia: ', teste_acuracia)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
