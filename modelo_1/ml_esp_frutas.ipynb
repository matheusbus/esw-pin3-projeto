{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbdc6dd-9bd7-4b67-9e31-81a5147a109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "260cbcc7-285c-4d54-b24d-327f00d2e1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de imagens de morango: 306\n",
      "Contagem de imagens de pêssego: 304\n",
      "Contagem de imagens de romã: 311\n"
     ]
    }
   ],
   "source": [
    "## 1. Dataset das imagens\n",
    "dataset_dir = os.path.join(os.getcwd(), 'imagens')\n",
    "dataset_morango_dir = os.path.join(dataset_dir, 'morango')\n",
    "dataset_pessego_dir = os.path.join(dataset_dir, 'pessego')\n",
    "dataset_roma_dir = os.path.join(dataset_dir, 'roma')\n",
    "\n",
    "dataset_morango_len = len(os.listdir(dataset_morango_dir))\n",
    "dataset_pessego_len = len(os.listdir(dataset_pessego_dir))\n",
    "dataset_roma_len = len(os.listdir(dataset_roma_dir))\n",
    "\n",
    "print(f'Contagem de imagens de morango: {dataset_morango_len}')\n",
    "print(f'Contagem de imagens de pêssego: {dataset_pessego_len}')\n",
    "print(f'Contagem de imagens de romã: {dataset_roma_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202294f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Aplicando o rebalanceamento do dataset\n",
    "# -> Utilizada a técnica de 'data augmentation' para gerar novas imagens de morango e pessego\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Criar um objeto ImageDataGenerator para data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,          # Faixa de rotação aleatória em graus\n",
    "    width_shift_range=0.2,      # Faixa de deslocamento horizontal aleatório (como uma fração da largura total)\n",
    "    height_shift_range=0.2,     # Faixa de deslocamento vertical aleatório (como uma fração da altura total)\n",
    "    shear_range=0.2,            # Faixa de cisalhamento aleatório (em radianos)\n",
    "    zoom_range=0.2,             # Faixa de zoom aleatório\n",
    "    horizontal_flip=True,      # Inverter aleatoriamente as imagens horizontalmente (espelhamento)\n",
    "    fill_mode='nearest'        # Estratégia de preenchimento usada para preencher novos pixels gerados após a rotação ou deslocamento\n",
    ")\n",
    "\n",
    "if (dataset_morango_len == 250) or (dataset_pessego_len == 250): \n",
    "    numero_imagens_aumentadas = 61\n",
    "    classes_aumentadas = ['morango', 'pessego']\n",
    "\n",
    "    for classe in classes_aumentadas:\n",
    "        # Diretório da classe atual\n",
    "        diretorio_classe = os.path.join(dataset_dir, classe)\n",
    "        \n",
    "        # Criar diretório para a classe aumentada, se não existir\n",
    "        diretorio_destino_classe = os.path.join(dataset_dir, classe)\n",
    "        os.makedirs(diretorio_destino_classe, exist_ok=True)\n",
    "        \n",
    "        # Lista de arquivos de imagem na classe atual\n",
    "        imagens_classe = os.listdir(diretorio_classe)\n",
    "        \n",
    "        # Selecionar aleatoriamente algumas imagens existentes para data augmentation\n",
    "        indices_amostra = np.random.choice(len(imagens_classe), numero_imagens_aumentadas, replace=True)\n",
    "        \n",
    "        # Para cada imagem de amostra selecionada\n",
    "        for indice in indices_amostra:\n",
    "            imagem_nome = imagens_classe[indice]\n",
    "            imagem_path = os.path.join(diretorio_classe, imagem_nome)\n",
    "            \n",
    "            # Carregar imagem\n",
    "            imagem = Image.open(imagem_path)\n",
    "            imagem_array = np.array(imagem)\n",
    "            imagem_array = imagem_array.reshape((1,) + imagem_array.shape)  # Reshape para (1, altura, largura, canais)\n",
    "            \n",
    "            # Gerar imagens aumentadas e salvar no diretório de destino\n",
    "            for i, batch in enumerate(datagen.flow(imagem_array, batch_size=1)):\n",
    "                if i >= 1:  # Quantidade de imagens aumentadas a serem geradas por imagem de amostra\n",
    "                    break\n",
    "                imagem_aumentada = batch[0].astype(np.uint8)  # Converter de volta para o formato de imagem\n",
    "                nova_imagem_nome = f\"{os.path.splitext(imagem_nome)[0]}_aug_{i}.jpg\"\n",
    "                nova_imagem_path = os.path.join(diretorio_destino_classe, nova_imagem_nome)\n",
    "                nova_imagem = Image.fromarray(imagem_aumentada)\n",
    "                nova_imagem.save(nova_imagem_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f11c96a-7b60-4ece-b705-d472939d7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Definição e separação dos dados de treinamento e dados de teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "projeto_dir = os.getcwd() # Diretório do projeto\n",
    "dataset_treinamento_dir = os.path.join(projeto_dir, 'imagens_treinamento') # Caminho para imagens_treinamento\n",
    "dataset_teste_dir = os.path.join(projeto_dir, 'imagens_teste') # Caminho para imagens_teste\n",
    "\n",
    "proporcao_dataset_treinamento = 0.8 # 80% será utilizado no treinamento\n",
    "proporcao_dataset_teste = 1 - proporcao_dataset_treinamento # 20% será utilizado no teste\n",
    "random_seed = 42 # A resposta para a Vida - segundo livro de Aurélien Géron - gerar com random\n",
    "\n",
    "classes = ['morango', 'pessego', 'roma']\n",
    "\n",
    "# Função que executará a separação das imagens (utiliza algoritmo de aleatoriedade)\n",
    "def split_dataset_to_train_and_test(classe):\n",
    "    dataset_treinamento_classe_dir = os.path.join(dataset_treinamento_dir, classe) # Dir. destino treinamento classe\n",
    "    dataset_teste_classe_dir = os.path.join(dataset_teste_dir, classe) # Dir. destino teste classe\n",
    "\n",
    "    dataset_classe_dir = os.path.join(projeto_dir, 'imagens', classe) # Dir. origem imagens classe\n",
    "    imagens_classe = [os.path.join(dataset_classe_dir, img) for img in os.listdir(dataset_classe_dir)] # Popular lista com imagens\n",
    "\n",
    "    imagens_treinamento_classe, imagens_teste_classe = train_test_split(imagens_classe, test_size=proporcao_dataset_teste, random_state=random_seed) # Algoritmo que separa aleatoriamente as imagens de treinamento e de teste\n",
    "\n",
    "    # Criação dos diretórios de treinamento e teste para a classe\n",
    "    os.makedirs(dataset_treinamento_classe_dir, exist_ok=True)\n",
    "    os.makedirs(dataset_teste_classe_dir, exist_ok=True)\n",
    "\n",
    "    # Copia as imagens de treinamento para a pasta de treinamento da classe em questão\n",
    "    for imagem in imagens_treinamento_classe:\n",
    "        shutil.copy(imagem, dataset_treinamento_classe_dir) \n",
    "\n",
    "    # Copia as imagens de teste para a pasta de teste da classe em questão\n",
    "    for imagem in imagens_teste_classe:\n",
    "        shutil.copy(imagem, dataset_teste_classe_dir) \n",
    "\n",
    "# Verifica se os diretórios de treinamento e teste já existem\n",
    "if not os.path.exists(dataset_treinamento_dir) or not os.path.exists(dataset_teste_dir):\n",
    "    # Cria os diretórios de treinamento e teste\n",
    "    os.makedirs(dataset_treinamento_dir, exist_ok=True)\n",
    "    os.makedirs(dataset_teste_dir, exist_ok=True)\n",
    "    # Para cada classe, executa a função de divisão de dados\n",
    "    for classe in classes:\n",
    "        split_dataset_to_train_and_test(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c7c32a-e4e8-435b-b67d-0e8ee0e51f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de imagens de morango para treinamento: 244\n",
      "Contagem de imagens de morango para teste: 62\n",
      "Contagem de imagens de pêssego para treinamento: 243\n",
      "Contagem de imagens de pêssego para teste: 61\n",
      "Contagem de imagens de romã para treinamento: 248\n",
      "Contagem de imagens de romã para teste: 63\n"
     ]
    }
   ],
   "source": [
    "# Como ficou dataset de treinamento e de testes:\n",
    "\n",
    "dataset_treinamento_morango_len = len(os.listdir(os.path.join(dataset_treinamento_dir, 'morango')))\n",
    "dataset_teste_morango_len = len(os.listdir(os.path.join(dataset_teste_dir, 'morango')))\n",
    "dataset_treinamento_pessego_len = len(os.listdir(os.path.join(dataset_treinamento_dir, 'pessego')))\n",
    "dataset_teste_pessego_len = len(os.listdir(os.path.join(dataset_teste_dir, 'pessego')))\n",
    "dataset_treinamento_roma_len = len(os.listdir(os.path.join(dataset_treinamento_dir, 'roma')))\n",
    "dataset_teste_roma_len = len(os.listdir(os.path.join(dataset_teste_dir, 'roma')))\n",
    "\n",
    "print(f'Contagem de imagens de morango para treinamento: {dataset_treinamento_morango_len}')\n",
    "print(f'Contagem de imagens de morango para teste: {dataset_teste_morango_len}')\n",
    "print(f'Contagem de imagens de pêssego para treinamento: {dataset_treinamento_pessego_len}')\n",
    "print(f'Contagem de imagens de pêssego para teste: {dataset_teste_pessego_len}')\n",
    "print(f'Contagem de imagens de romã para treinamento: {dataset_treinamento_roma_len}')\n",
    "print(f'Contagem de imagens de romã para teste: {dataset_teste_roma_len}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e820b6a-891f-4d1d-8934-59dc4f5c427f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matheus/Documentos/GitHub/esw-pin3-projeto/modelo_1/imagens_treinamento\n",
      "/home/matheus/Documentos/GitHub/esw-pin3-projeto/modelo_1/imagens_teste\n",
      "Found 735 files belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 186 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "## 4. Pré-processamento das imagens\n",
    "## --> Definir tamanho de entrada das minhas imagens (em px)\n",
    "## --> Definir qual estratégia de conversão adotar (scaling da imagem / foco no centro da imagem ignorando periferia / recortar imagem até no limite do tamanho definido e ignorar o restante)\n",
    "\n",
    "'''\n",
    "Considerações sobre a abordagem:\n",
    "O pré-processamento é feito pela função \"tf.keras.preprocessing.image_dataset_from_directory\". Essa função permite especificar o tamanho das imagens e aplica automaticamente a normalização durante o carregamento das imagens. Além disso, aplica embaralhamento\n",
    "e carrega as imagens em lotes (batch). Por fim, as imagens são consideradas como tensores do TensorFlow.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "image_width = 300\n",
    "image_heigth = 300\n",
    "image_size = (image_width, image_heigth)\n",
    "\n",
    "image_color_channel = 3\n",
    "image_color_channel_size = 255\n",
    "image_shape = image_size + (image_color_channel,)\n",
    "\n",
    "batch_size = 32 # Valor que vou puxar do dataset por vez\n",
    "epoch = 20 # Quantidade de vezes que vou percorrer meu dataset inteiro\n",
    "learning_rate = 0.0001 # Taxa de aprendizagem\n",
    "\n",
    "classes = ['morango', 'pessego', 'roma']\n",
    "\n",
    "projeto_dir = os.getcwd()\n",
    "dataset_treinamento_dir = os.path.join(projeto_dir, 'imagens_treinamento')\n",
    "dataset_teste_dir = os.path.join(projeto_dir, 'imagens_teste')\n",
    "\n",
    "print(dataset_treinamento_dir)\n",
    "print(dataset_teste_dir)\n",
    "\n",
    "data_set_treinamento = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_treinamento_dir,\n",
    "    image_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True, # Embaralhamento\n",
    "    label_mode='categorical' # Carrega os dados em formato one-hot\n",
    ")\n",
    "\n",
    "data_set_teste = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_teste_dir,\n",
    "    image_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False, # Não é necessário embaralhar os dados de teste\n",
    "    label_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fe27dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Definição da arquitetura da rede neural do modelo\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "\n",
    "\n",
    "# Arquitetura da rede do modelo implementado:\n",
    "model = Sequential([\n",
    "  # Definição do tipo de entrada: imagens de 300x300 pixels com 3 canais de cores (RGB) \n",
    "  Input(shape=(300,300,3)),\n",
    "\n",
    "  # Primeira camada: convolucional com 32 filtros de tamanho 3x3, utilizando a função de ativação ReLU\n",
    "  Conv2D(32, (3,3), activation='relu'),\n",
    "\n",
    "  # Camada de normalização de batch, para normalizar a ativação da camada anterior\n",
    "  BatchNormalization(),\n",
    "\n",
    "  # Camada de MaxPooling, detalhada no documento de especificação do projeto\n",
    "  MaxPooling2D((2,2)),\n",
    "\n",
    "  # Mais uma camada Conv2D, com 64 filtros de tamanho 3x3, com função de ativação ReLU\n",
    "  Conv2D(64, (3,3), activation='relu'),\n",
    "\n",
    "  # Outra camada de normalização de batch, para normalizar a ativação da camada anterior\n",
    "  BatchNormalization(),\n",
    "\n",
    "  # Camada de MaxPooling, detalhada no documento de especificação do projeto\n",
    "  MaxPooling2D((2,2)),\n",
    "\n",
    "  # Camada de achatamento (Flatten) para transformar os mapas de características 2D em um vetor 1D\n",
    "  Flatten(),\n",
    "  \n",
    "  # Camada densa (totalmente conectada) com 128 neurônios e função de ativação ReLU\n",
    "  Dense(128, activation='relu'),\n",
    "  \n",
    "  # Mias uma camada de normalização de batch, para normalizar a ativação da camada anterior\n",
    "  BatchNormalization(),\n",
    "\n",
    "  # Mais uma camada densa com 64 neurônios e função de ativação ReLU\n",
    "  Dense(64, activation='relu'),\n",
    "  \n",
    "  # Camada de Dropout para prevenir overfitting, desativando aleatoriamente 50% dos neurônios\n",
    "  Dropout(0.5),\n",
    "  \n",
    "  # Camada de saída com 3 neurônios (um para cada classe) e função de ativação softmax para a classificação multiclasse\n",
    "  Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilação do modelo\n",
    "# Aqui, utilizamos a função de perda conforme espeficicado no documento do projeto\n",
    "# Função de perda: crossentropy, que irá calcular a diferença entre as previsões realizadas pelo modelo e os rótulos verdadeiros associados aos dados de treinamento.\n",
    "\n",
    "# Além disso, testaremos 3 tipos de funções de otimização:\n",
    "\n",
    "# Função de otimização Adam\n",
    "model.compile(optimizer=Adam(learning_rate), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "# Função de otimização SGD\n",
    "# model.compile(optimizer=SGD(), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "# Função de otimização RMSprop\n",
    "# model.compile(optimizer=RMSprop(), loss=CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bc18158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 6s/step - accuracy: 0.5911 - loss: 1.2363 - val_accuracy: 0.4355 - val_loss: 8.8659\n",
      "Epoch 2/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 6s/step - accuracy: 0.7868 - loss: 0.5642 - val_accuracy: 0.5914 - val_loss: 2.7070\n",
      "Epoch 3/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 5s/step - accuracy: 0.8734 - loss: 0.3712 - val_accuracy: 0.5269 - val_loss: 1.4865\n",
      "Epoch 4/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 5s/step - accuracy: 0.9033 - loss: 0.2868 - val_accuracy: 0.6183 - val_loss: 0.8187\n",
      "Epoch 5/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 5s/step - accuracy: 0.9235 - loss: 0.2405 - val_accuracy: 0.8172 - val_loss: 0.4999\n",
      "Epoch 6/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 5s/step - accuracy: 0.9510 - loss: 0.1896 - val_accuracy: 0.8333 - val_loss: 0.4396\n",
      "Epoch 7/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 6s/step - accuracy: 0.9582 - loss: 0.1524 - val_accuracy: 0.8602 - val_loss: 0.4129\n",
      "Epoch 8/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - accuracy: 0.9662 - loss: 0.1233 - val_accuracy: 0.8763 - val_loss: 0.3867\n",
      "Epoch 9/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 6s/step - accuracy: 0.9788 - loss: 0.0963 - val_accuracy: 0.8656 - val_loss: 0.4254\n",
      "Epoch 10/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 6s/step - accuracy: 0.9845 - loss: 0.0770 - val_accuracy: 0.8656 - val_loss: 0.4310\n",
      "Epoch 11/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 6s/step - accuracy: 0.9843 - loss: 0.0859 - val_accuracy: 0.8656 - val_loss: 0.4473\n",
      "Epoch 12/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 5s/step - accuracy: 0.9880 - loss: 0.0794 - val_accuracy: 0.8226 - val_loss: 0.4913\n",
      "Epoch 13/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 6s/step - accuracy: 0.9875 - loss: 0.0636 - val_accuracy: 0.8280 - val_loss: 0.4568\n",
      "Epoch 14/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 6s/step - accuracy: 0.9968 - loss: 0.0386 - val_accuracy: 0.8495 - val_loss: 0.4610\n",
      "Epoch 15/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 6s/step - accuracy: 0.9975 - loss: 0.0378 - val_accuracy: 0.8495 - val_loss: 0.4956\n",
      "Epoch 16/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 6s/step - accuracy: 0.9930 - loss: 0.0460 - val_accuracy: 0.8387 - val_loss: 0.5088\n",
      "Epoch 17/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 5s/step - accuracy: 0.9943 - loss: 0.0385 - val_accuracy: 0.8710 - val_loss: 0.5150\n",
      "Epoch 18/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 7s/step - accuracy: 0.9975 - loss: 0.0313 - val_accuracy: 0.8118 - val_loss: 0.6048\n",
      "Epoch 19/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 7s/step - accuracy: 0.9944 - loss: 0.0367 - val_accuracy: 0.7957 - val_loss: 0.6911\n",
      "Epoch 20/20\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 7s/step - accuracy: 1.0000 - loss: 0.0261 - val_accuracy: 0.8441 - val_loss: 0.4956\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8377 - loss: 0.4545\n",
      "Teste acurácia:  0.8440860509872437\n"
     ]
    }
   ],
   "source": [
    "# 6. Treinamento do modelo\n",
    "\n",
    "# É passado o dataset de treinamento, a quantidade de épocas (quantas vezes vai percorrer o dataset) e o dataset de validação\n",
    "model.fit(\n",
    "  data_set_treinamento,\n",
    "  epochs=epoch,\n",
    "  validation_data=data_set_teste\n",
    ")\n",
    "\n",
    "# Avaliação do modelo\n",
    "teste_perca, teste_acuracia = model.evaluate(data_set_teste)\n",
    "print('Teste acurácia: ', teste_acuracia)\n",
    "\n",
    "'''\n",
    "Epochs: Cada linha corresponde a uma época de treinamento. Uma época é uma iteração completa sobre todo o conjunto de dados de treinamento.\n",
    "\n",
    "Batches por Época: Aqui, o número 23/23 indica que há 23 batches (ou lotes) de dados sendo processados em cada época. Isso pode variar dependendo do tamanho do conjunto de treinamento e do tamanho do lote (batch_size). Por exemplo, se você tem 700 amostras de treinamento e está usando um tamanho de lote de 32, então cada época terá 22 batches (700/32 = 21.875).\n",
    "\n",
    "Tempo por Época: O tempo indicado representa o tempo gasto para completar uma época. Isso pode variar dependendo da complexidade do modelo, tamanho do conjunto de dados e recursos do hardware.\n",
    "\n",
    "Accuracy (Acurácia) e Loss (Perda): A acurácia e a perda durante o treinamento e validação são mostradas para cada época. A acurácia indica a proporção de previsões corretas em relação ao total de exemplos, enquanto a perda (loss) é uma medida do quão bem o modelo está performando durante o treinamento, sendo minimizada ao longo das épocas.\n",
    "\n",
    "Val_accuracy e Val_loss: Estes são os valores de acurácia e perda calculados no conjunto de dados de validação, que é usado para avaliar o desempenho do modelo em dados que não foram vistos durante o treinamento. É importante monitorar essas métricas para evitar overfitting e garantir que o modelo esteja generalizando bem para novos dados.\n",
    "\n",
    "Test accuracy e Test loss: Após o treinamento, o modelo é avaliado no conjunto de dados de teste (geralmente separado do conjunto de validação). Estas métricas fornecem uma avaliação final do desempenho do modelo em dados completamente novos e não vistos durante o treinamento.\n",
    "\n",
    "Acurácia: No final do treinamento, a acurácia nos dados de validação foi de aproximadamente 84.41%. Isso significa que o modelo classificou corretamente cerca de 84.41% das amostras nos dados de validação.\n",
    "\n",
    "Perda: A perda nos dados de validação foi de aproximadamente 0.4956. A perda é uma medida de quão boa ou ruim é a previsão do modelo para uma única amostra; valores mais baixos são melhores.\n",
    "\n",
    "Tendência ao longo das épocas: A acurácia e a perda parecem estar se estabilizando ao longo das épocas, o que sugere que o modelo está convergindo para uma solução.\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
