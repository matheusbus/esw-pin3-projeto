{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fbdc6dd-9bd7-4b67-9e31-81a5147a109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "260cbcc7-285c-4d54-b24d-327f00d2e1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de imagens de morango: 250\n",
      "Contagem de imagens de pêssego: 250\n",
      "Contagem de imagens de romã: 311\n"
     ]
    }
   ],
   "source": [
    "## 1. Dataset das imagens\n",
    "dataset_dir = os.path.join(os.getcwd(), 'imagens')\n",
    "dataset_morango_dir = os.path.join(dataset_dir, 'morango')\n",
    "dataset_pessego_dir = os.path.join(dataset_dir, 'pessego')\n",
    "dataset_roma_dir = os.path.join(dataset_dir, 'roma')\n",
    "\n",
    "dataset_morango_len = len(os.listdir(dataset_morango_dir))\n",
    "dataset_pessego_len = len(os.listdir(dataset_pessego_dir))\n",
    "dataset_roma_len = len(os.listdir(dataset_roma_dir))\n",
    "\n",
    "print(f'Contagem de imagens de morango: {dataset_morango_len}')\n",
    "print(f'Contagem de imagens de pêssego: {dataset_pessego_len}')\n",
    "print(f'Contagem de imagens de romã: {dataset_roma_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3edbe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Carregamento das imagens e pré-processamento\n",
    "# -> Normalização dos pixels das imagens para o intervalo [0,1]\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "dataset_dir = os.path.join(os.getcwd(), 'imagens')\n",
    "classes = ['morango', 'pessego', 'roma']\n",
    "\n",
    "def carregar_imagens(diretorio_base, tamanho=(500, 500)):\n",
    "    imagens = []\n",
    "    rotulos = []\n",
    "    for rotulo, pasta in enumerate(['morango', 'pessego', 'roma']):\n",
    "        pasta_path = os.path.join(diretorio_base, pasta)\n",
    "        for imagem_nome in os.listdir(pasta_path):\n",
    "            imagem_path = os.path.join(pasta_path, imagem_nome)\n",
    "            imagem = Image.open(imagem_path)\n",
    "            imagem = imagem.resize(tamanho)\n",
    "            imagem_array = np.array(imagem) / 255.0  # Normalizar para o intervalo [0, 1]\n",
    "            imagens.append(imagem_array)\n",
    "            rotulos.append(rotulo)  # Usando o índice como rótulo\n",
    "    return np.array(imagens), np.array(rotulos)\n",
    "\n",
    "X, Y = carregar_imagens(dataset_dir)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202294f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Aplicando o rebalanceamento do dataset\n",
    "# -> Utilizada a técnica de 'data augmentation' para gerar novas imagens de morango e pessego\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Criar um objeto ImageDataGenerator para data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,          # Faixa de rotação aleatória em graus\n",
    "    width_shift_range=0.2,      # Faixa de deslocamento horizontal aleatório (como uma fração da largura total)\n",
    "    height_shift_range=0.2,     # Faixa de deslocamento vertical aleatório (como uma fração da altura total)\n",
    "    shear_range=0.2,            # Faixa de cisalhamento aleatório (em radianos)\n",
    "    zoom_range=0.2,             # Faixa de zoom aleatório\n",
    "    horizontal_flip=True,      # Inverter aleatoriamente as imagens horizontalmente (espelhamento)\n",
    "    fill_mode='nearest'        # Estratégia de preenchimento usada para preencher novos pixels gerados após a rotação ou deslocamento\n",
    ")\n",
    "\n",
    "numero_imagens_aumentadas = 61\n",
    "classes_aumentadas = ['morango', 'pessego']\n",
    "\n",
    "for classe in classes_aumentadas:\n",
    "    # Diretório da classe atual\n",
    "    diretorio_classe = os.path.join(dataset_dir, classe)\n",
    "    \n",
    "    # Criar diretório para a classe aumentada, se não existir\n",
    "    diretorio_destino_classe = os.path.join(dataset_dir, classe)\n",
    "    os.makedirs(diretorio_destino_classe, exist_ok=True)\n",
    "    \n",
    "    # Lista de arquivos de imagem na classe atual\n",
    "    imagens_classe = os.listdir(diretorio_classe)\n",
    "    \n",
    "    # Selecionar aleatoriamente algumas imagens existentes para data augmentation\n",
    "    indices_amostra = np.random.choice(len(imagens_classe), numero_imagens_aumentadas, replace=True)\n",
    "    \n",
    "    # Para cada imagem de amostra selecionada\n",
    "    for indice in indices_amostra:\n",
    "        imagem_nome = imagens_classe[indice]\n",
    "        imagem_path = os.path.join(diretorio_classe, imagem_nome)\n",
    "        \n",
    "        # Carregar imagem\n",
    "        imagem = Image.open(imagem_path)\n",
    "        imagem_array = np.array(imagem)\n",
    "        imagem_array = imagem_array.reshape((1,) + imagem_array.shape)  # Reshape para (1, altura, largura, canais)\n",
    "        \n",
    "        # Gerar imagens aumentadas e salvar no diretório de destino\n",
    "        for i, batch in enumerate(datagen.flow(imagem_array, batch_size=1)):\n",
    "            if i >= 1:  # Quantidade de imagens aumentadas a serem geradas por imagem de amostra\n",
    "                break\n",
    "            imagem_aumentada = batch[0].astype(np.uint8)  # Converter de volta para o formato de imagem\n",
    "            nova_imagem_nome = f\"{os.path.splitext(imagem_nome)[0]}_aug_{i}.jpg\"\n",
    "            nova_imagem_path = os.path.join(diretorio_destino_classe, nova_imagem_nome)\n",
    "            nova_imagem = Image.fromarray(imagem_aumentada)\n",
    "            nova_imagem.save(nova_imagem_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f11c96a-7b60-4ece-b705-d472939d7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Definição e separação dos dados de treinamento e dados de teste\n",
    "projeto_dir = os.getcwd() # Diretório do projeto\n",
    "dataset_treinamento_dir = os.path.join(projeto_dir, 'imagens_treinamento') # Caminho para imagens_treinamento\n",
    "dataset_teste_dir = os.path.join(projeto_dir, 'imagens_teste') # Caminho para imagens_teste\n",
    "\n",
    "proporcao_dataset_treinamento = 0.8 # 80% será utilizado no treinamento\n",
    "proporcao_dataset_teste = 1 - proporcao_dataset_treinamento # 20% será utilizado no teste\n",
    "random_seed = 42 # A resposta para a Vida - segundo livro de Aurélien Géron - gerar com random\n",
    "\n",
    "classes = ['morango', 'pessego', 'roma']\n",
    "\n",
    "# Função que executará a separação das imagens (utiliza algoritmo de aleatoriedade)\n",
    "def split_dataset_to_train_and_test(classe):\n",
    "    dataset_treinamento_classe_dir = os.path.join(dataset_treinamento_dir, classe) # Dir. destino treinamento classe\n",
    "    dataset_teste_classe_dir = os.path.join(dataset_teste_dir, classe) # Dir. destino teste classe\n",
    "\n",
    "    dataset_classe_dir = os.path.join(projeto_dir, 'imagens', classe) # Dir. origem imagens classe\n",
    "    imagens_classe = [os.path.join(dataset_classe_dir, img) for img in os.listdir(dataset_classe_dir)] # Popular lista com imagens\n",
    "\n",
    "    imagens_treinamento_classe, imagens_teste_classe = train_test_split(imagens_classe, test_size=proporcao_dataset_teste, random_state=random_seed) # Algoritmo que separa aleatoriamente as imagens de treinamento e de teste\n",
    "\n",
    "    # Criação dos diretórios de treinamento e teste para a classe\n",
    "    os.makedirs(dataset_treinamento_classe_dir, exist_ok=True)\n",
    "    os.makedirs(dataset_teste_classe_dir, exist_ok=True)\n",
    "\n",
    "    # Copia as imagens de treinamento para a pasta de treinamento da classe em questão\n",
    "    for imagem in imagens_treinamento_classe:\n",
    "        shutil.copy(imagem, dataset_treinamento_classe_dir) \n",
    "\n",
    "    # Copia as imagens de teste para a pasta de teste da classe em questão\n",
    "    for imagem in imagens_teste_classe:\n",
    "        shutil.copy(imagem, dataset_teste_classe_dir) \n",
    "\n",
    "# Verifica se os diretórios de treinamento e teste já existem\n",
    "if not os.path.exists(dataset_treinamento_dir) or not os.path.exists(dataset_teste_dir):\n",
    "    # Cria os diretórios de treinamento e teste\n",
    "    os.makedirs(dataset_treinamento_dir, exist_ok=True)\n",
    "    os.makedirs(dataset_teste_dir, exist_ok=True)\n",
    "    # Para cada classe, executa a função de divisão de dados\n",
    "    for classe in classes:\n",
    "        split_dataset_to_train_and_test(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60c7c32a-e4e8-435b-b67d-0e8ee0e51f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem de imagens de morango para treinamento: 200\n",
      "Contagem de imagens de morango para teste: 50\n",
      "Contagem de imagens de pêssego para treinamento: 200\n",
      "Contagem de imagens de pêssego para teste: 50\n",
      "Contagem de imagens de romã para treinamento: 248\n",
      "Contagem de imagens de romã para teste: 63\n"
     ]
    }
   ],
   "source": [
    "## 1.3. Como ficou dataset de treinamento e de testes:\n",
    "\n",
    "dataset_treinamento_morango_len = len(os.listdir(os.path.join(dataset_treinamento_dir, 'morango')))\n",
    "dataset_teste_morango_len = len(os.listdir(os.path.join(dataset_teste_dir, 'morango')))\n",
    "dataset_treinamento_pessego_len = len(os.listdir(os.path.join(dataset_treinamento_dir, 'pessego')))\n",
    "dataset_teste_pessego_len = len(os.listdir(os.path.join(dataset_teste_dir, 'morango')))\n",
    "dataset_treinamento_roma_len = len(os.listdir(os.path.join(dataset_treinamento_dir, 'roma')))\n",
    "dataset_teste_roma_len = len(os.listdir(os.path.join(dataset_teste_dir, 'roma')))\n",
    "\n",
    "print(f'Contagem de imagens de morango para treinamento: {dataset_treinamento_morango_len}')\n",
    "print(f'Contagem de imagens de morango para teste: {dataset_teste_morango_len}')\n",
    "print(f'Contagem de imagens de pêssego para treinamento: {dataset_treinamento_pessego_len}')\n",
    "print(f'Contagem de imagens de pêssego para teste: {dataset_teste_pessego_len}')\n",
    "print(f'Contagem de imagens de romã para treinamento: {dataset_treinamento_roma_len}')\n",
    "print(f'Contagem de imagens de romã para teste: {dataset_teste_roma_len}')\n",
    "\n",
    "# desbalanceamento para a classe de romã\n",
    "# considerar balancear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e820b6a-891f-4d1d-8934-59dc4f5c427f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 648 files belonging to 3 classes.\n",
      "Found 163 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "## 2. Pré-processamento das imagens\n",
    "## --> Definir tamanho de entrada das minhas imagens (em px)\n",
    "## --> Definir qual estratégia de conversão adotar (scaling da imagem / foco no centro da imagem ignorando periferia / recortar imagem até\n",
    "## no limite do tamanho definido e ignorar o restante)\n",
    "\n",
    "image_width = 160\n",
    "image_heigth = 160\n",
    "image_size = (image_width, image_heigth)\n",
    "\n",
    "image_color_channel = 3\n",
    "image_color_channel_size = 255\n",
    "image_shape = image_size + (image_color_channel,)\n",
    "\n",
    "batch_size = 32 # Valor que vou puxar do dataset por vez\n",
    "epoch = 20 # Quantidade de vezes que vou percorrer meu dataset inteiro\n",
    "learning_rate = 0.0001 # Taxa de aprendizagem\n",
    "\n",
    "classes = ['morango', 'pessego', 'roma']\n",
    "\n",
    "data_set_treinamento = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_treinamento_dir,\n",
    "    image_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "data_set_teste = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_teste_dir,\n",
    "    image_size = image_size,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb697999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10355ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
